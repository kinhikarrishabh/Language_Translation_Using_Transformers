{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-24T19:29:57.144448Z",
     "iopub.status.busy": "2022-04-24T19:29:57.144085Z",
     "iopub.status.idle": "2022-04-24T19:30:03.097782Z",
     "shell.execute_reply": "2022-04-24T19:30:03.096810Z",
     "shell.execute_reply.started": "2022-04-24T19:29:57.144361Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from string import punctuation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:03.100158Z",
     "iopub.status.busy": "2022-04-24T19:30:03.099873Z",
     "iopub.status.idle": "2022-04-24T19:30:04.835010Z",
     "shell.execute_reply": "2022-04-24T19:30:04.833800Z",
     "shell.execute_reply.started": "2022-04-24T19:30:03.100116Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('russian_to_english/rus.txt',delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:04.836951Z",
     "iopub.status.busy": "2022-04-24T19:30:04.836625Z",
     "iopub.status.idle": "2022-04-24T19:30:04.860216Z",
     "shell.execute_reply": "2022-04-24T19:30:04.859114Z",
     "shell.execute_reply.started": "2022-04-24T19:30:04.836909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Марш!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Иди.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Идите.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Здравствуйте.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Привет!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0              1                                                  2\n",
       "0  Go.          Марш!  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1  Go.           Иди.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2  Go.         Идите.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3  Hi.  Здравствуйте.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "4  Hi.        Привет!  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:04.975564Z",
     "iopub.status.busy": "2022-04-24T19:30:04.975335Z",
     "iopub.status.idle": "2022-04-24T19:30:04.980568Z",
     "shell.execute_reply": "2022-04-24T19:30:04.979388Z",
     "shell.execute_reply.started": "2022-04-24T19:30:04.975534Z"
    }
   },
   "outputs": [],
   "source": [
    "data=data.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:06.999024Z",
     "iopub.status.busy": "2022-04-24T19:30:06.998520Z",
     "iopub.status.idle": "2022-04-24T19:30:07.008802Z",
     "shell.execute_reply": "2022-04-24T19:30:07.007726Z",
     "shell.execute_reply.started": "2022-04-24T19:30:06.998991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Марш!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Иди.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Идите.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Здравствуйте.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Привет!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0              1\n",
       "0  Go.          Марш!\n",
       "1  Go.           Иди.\n",
       "2  Go.         Идите.\n",
       "3  Hi.  Здравствуйте.\n",
       "4  Hi.        Привет!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:08.383881Z",
     "iopub.status.busy": "2022-04-24T19:30:08.383544Z",
     "iopub.status.idle": "2022-04-24T19:30:08.391120Z",
     "shell.execute_reply": "2022-04-24T19:30:08.389996Z",
     "shell.execute_reply.started": "2022-04-24T19:30:08.383849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1], dtype='int64')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:09.213845Z",
     "iopub.status.busy": "2022-04-24T19:30:09.212464Z",
     "iopub.status.idle": "2022-04-24T19:30:09.219942Z",
     "shell.execute_reply": "2022-04-24T19:30:09.218897Z",
     "shell.execute_reply.started": "2022-04-24T19:30:09.213778Z"
    }
   },
   "outputs": [],
   "source": [
    "data.rename(columns={0: \"English\", 1: \"Russian\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:10.327865Z",
     "iopub.status.busy": "2022-04-24T19:30:10.326337Z",
     "iopub.status.idle": "2022-04-24T19:30:10.335010Z",
     "shell.execute_reply": "2022-04-24T19:30:10.333743Z",
     "shell.execute_reply.started": "2022-04-24T19:30:10.327805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['English', 'Russian'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:11.595380Z",
     "iopub.status.busy": "2022-04-24T19:30:11.594783Z",
     "iopub.status.idle": "2022-04-24T19:30:21.007428Z",
     "shell.execute_reply": "2022-04-24T19:30:21.006451Z",
     "shell.execute_reply.started": "2022-04-24T19:30:11.595344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "# Clean the string\n",
    "def clean_string(string):\n",
    "    # Replace no-break space with space\n",
    "    string = string.replace(\"\\u202f\",\" \")\n",
    "    # Converts all uppercase characters into lowercase characters\n",
    "    string = string.lower()\n",
    "\n",
    "    # Delete the punctuation and the numbers\n",
    "    for p in punctuation + \"«»\" + \"0123456789\":\n",
    "        string = string.replace(p,\" \")\n",
    "\n",
    "    # Eliminate duplicate whitespaces using wildcards   \n",
    "    string = re.sub(\"\\s+\",\" \", string)\n",
    "    # Remove spaces at the beginning and at the end of the string\n",
    "    string = string.strip()\n",
    "           \n",
    "    return string\n",
    "#-------------------------------------------------------------------------------\n",
    "# object to string\n",
    "data['English'] = data['English'].astype(str)\n",
    "data['Russian'] = data['Russian'].astype(str)\n",
    "\n",
    "# Clean the sentences\n",
    "data['English'] = data['English'].apply(lambda x: clean_string(x))\n",
    "data['Russian'] = data['Russian'].apply(lambda x: clean_string(x))\n",
    "\n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:21.011006Z",
     "iopub.status.busy": "2022-04-24T19:30:21.010101Z",
     "iopub.status.idle": "2022-04-24T19:30:21.022691Z",
     "shell.execute_reply": "2022-04-24T19:30:21.021709Z",
     "shell.execute_reply.started": "2022-04-24T19:30:21.010963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Russian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>марш</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>иди</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go</td>\n",
       "      <td>идите</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi</td>\n",
       "      <td>здравствуйте</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>привет</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English       Russian\n",
       "0      go          марш\n",
       "1      go           иди\n",
       "2      go         идите\n",
       "3      hi  здравствуйте\n",
       "4      hi        привет"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:21.024807Z",
     "iopub.status.busy": "2022-04-24T19:30:21.023906Z",
     "iopub.status.idle": "2022-04-24T19:30:21.168583Z",
     "shell.execute_reply": "2022-04-24T19:30:21.167585Z",
     "shell.execute_reply.started": "2022-04-24T19:30:21.024752Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_en = data[\"English\"].values\n",
    "raw_data_ru = data[\"Russian\"].values\n",
    "\n",
    "# Add start and end\n",
    "raw_data_ru_in_out = [\"[start] \" + st + \" [end]\" for st in raw_data_ru]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:22.117704Z",
     "iopub.status.busy": "2022-04-24T19:30:22.117216Z",
     "iopub.status.idle": "2022-04-24T19:30:22.336947Z",
     "shell.execute_reply": "2022-04-24T19:30:22.336017Z",
     "shell.execute_reply.started": "2022-04-24T19:30:22.117633Z"
    }
   },
   "outputs": [],
   "source": [
    "my_data = []\n",
    "for i in range(len(raw_data_en)):\n",
    "    en = raw_data_en[i]\n",
    "    ru = raw_data_ru_in_out[i]\n",
    "    my_data.append((en, ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:28.279878Z",
     "iopub.status.busy": "2022-04-24T19:30:28.279589Z",
     "iopub.status.idle": "2022-04-24T19:30:28.286107Z",
     "shell.execute_reply": "2022-04-24T19:30:28.285229Z",
     "shell.execute_reply.started": "2022-04-24T19:30:28.279842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('go', '[start] марш [end]'),\n",
       " ('go', '[start] иди [end]'),\n",
       " ('go', '[start] идите [end]'),\n",
       " ('hi', '[start] здравствуйте [end]'),\n",
       " ('hi', '[start] привет [end]')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:35.521533Z",
     "iopub.status.busy": "2022-04-24T19:30:35.520770Z",
     "iopub.status.idle": "2022-04-24T19:30:36.054042Z",
     "shell.execute_reply": "2022-04-24T19:30:36.053107Z",
     "shell.execute_reply.started": "2022-04-24T19:30:35.521482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "random.shuffle(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:40.800854Z",
     "iopub.status.busy": "2022-04-24T19:30:40.800522Z",
     "iopub.status.idle": "2022-04-24T19:30:40.823210Z",
     "shell.execute_reply": "2022-04-24T19:30:40.821789Z",
     "shell.execute_reply.started": "2022-04-24T19:30:40.800821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total russian in my dtat :  363386\n",
      "Training russian         :  254372\n",
      "Validation russian       :  54507\n",
      "Test russian             :  54507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train_set = 70%, Test_set = 15%, Val_set = 15%\n",
    "num_val_samples = int(0.15 * len(my_data))\n",
    "num_train_samples = len(my_data) - 2 * num_val_samples\n",
    "\n",
    "train_Russian = my_data[:num_train_samples]\n",
    "val_Russian  = my_data[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_Russian  = my_data[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(\"Total russian in my dtat : \",len(my_data))\n",
    "print(\"Training russian         : \",len(train_Russian))\n",
    "print(\"Validation russian       : \",len(val_Russian))\n",
    "print(\"Test russian             : \",len(test_Russian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:30:52.094295Z",
     "iopub.status.busy": "2022-04-24T19:30:52.094006Z",
     "iopub.status.idle": "2022-04-24T19:32:01.095597Z",
     "shell.execute_reply": "2022-04-24T19:32:01.094315Z",
     "shell.execute_reply.started": "2022-04-24T19:30:52.094265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing the text data\n",
    "vocab_size      = 15000\n",
    "sequence_length = 20\n",
    "batch_size      = 256\n",
    "\n",
    "en_vectorization = TextVectorization(\n",
    "    max_tokens = vocab_size, output_mode = \"int\", \n",
    "    output_sequence_length = sequence_length,)\n",
    "\n",
    "ru_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,)\n",
    "\n",
    "train_en_texts = [pair[0] for pair in train_Russian]\n",
    "train_ru_texts = [pair[1] for pair in train_Russian]\n",
    "\n",
    "en_vectorization.adapt(train_en_texts)\n",
    "ru_vectorization.adapt(train_ru_texts)\n",
    " \n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:35:02.719118Z",
     "iopub.status.busy": "2022-04-24T19:35:02.718841Z",
     "iopub.status.idle": "2022-04-24T19:35:08.699496Z",
     "shell.execute_reply": "2022-04-24T19:35:08.698431Z",
     "shell.execute_reply.started": "2022-04-24T19:35:02.719089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (256, 20)\n",
      "inputs[\"decoder_inputs\"].shape: (256, 20)\n",
      "targets.shape: (256, 20)\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(en, fr):\n",
    "    en = en_vectorization(en)\n",
    "    fr = ru_vectorization(fr)\n",
    "    return ({\"encoder_inputs\": en, \"decoder_inputs\": fr[:, :-1],}, fr[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    en_texts, fr_texts = zip(*pairs)\n",
    "\n",
    "    en_texts = list(en_texts)\n",
    "    fr_texts = list(fr_texts)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((en_texts, fr_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(train_Russian)\n",
    "val_dataset   = make_dataset(val_Russian)\n",
    "\n",
    "for inputs, targets in train_dataset.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:35:13.286575Z",
     "iopub.status.busy": "2022-04-24T19:35:13.285486Z",
     "iopub.status.idle": "2022-04-24T19:35:13.297324Z",
     "shell.execute_reply": "2022-04-24T19:35:13.296247Z",
     "shell.execute_reply.started": "2022-04-24T19:35:13.286542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "         #-----------------------------------------------------------------------\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size      = vocab_size\n",
    "        self.embed_dim       = embed_dim\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L3\n",
    "        self.input_embeddings = layers.Embedding(\n",
    "                                     input_dim=vocab_size, output_dim=embed_dim)\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "        # L4\n",
    "        self.positional_encoding = layers.Embedding(\n",
    "                                input_dim=sequence_length, output_dim=embed_dim)\n",
    "       \n",
    "    #---------------------------------------------------------------------------\n",
    "    def call(self, inputs):\n",
    "        length    = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "\n",
    "        # L3\n",
    "        embedded_inputs    = self.input_embeddings(inputs)\n",
    "        # L4\n",
    "        embedded_positions = self.positional_encoding(positions)\n",
    "        # L5\n",
    "        return embedded_inputs + embedded_positions\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "        \n",
    "#*******************************************************************************\n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:35:13.699091Z",
     "iopub.status.busy": "2022-04-24T19:35:13.698750Z",
     "iopub.status.idle": "2022-04-24T19:35:13.710621Z",
     "shell.execute_reply": "2022-04-24T19:35:13.709537Z",
     "shell.execute_reply.started": "2022-04-24T19:35:13.699059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        #-----------------------------------------------------------------------\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        # L6\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "                                         num_heads=num_heads, key_dim=embed_dim)\n",
    "        # L8\n",
    "        self.feed_forward = keras.Sequential([\n",
    "                                  layers.Dense(dense_dim, activation=\"relu\"), \n",
    "                                   layers.Dense(embed_dim),])\n",
    "        \n",
    "        # L7\n",
    "        self.normalization_1  = layers.LayerNormalization()\n",
    "        # L9\n",
    "        self.normalization_2  = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L6\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask)\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "        # L7\n",
    "        addnorm_output_1 = self.normalization_1(inputs + attention_output)\n",
    "        # L8\n",
    "        feedforward_output = self.feed_forward(addnorm_output_1)\n",
    "        # L9\n",
    "        addnorm_output_2 = self.normalization_2(addnorm_output_1 + feedforward_output)\n",
    "        # L10\n",
    "        return addnorm_output_2\n",
    "\n",
    "#*******************************************************************************\n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:35:14.185379Z",
     "iopub.status.busy": "2022-04-24T19:35:14.184998Z",
     "iopub.status.idle": "2022-04-24T19:35:14.203954Z",
     "shell.execute_reply": "2022-04-24T19:35:14.202929Z",
     "shell.execute_reply.started": "2022-04-24T19:35:14.185346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        #-----------------------------------------------------------------------\n",
    "        self.embed_dim  = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads  = num_heads\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L11\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "                                         num_heads=num_heads, key_dim=embed_dim)\n",
    "        # L13\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "                                         num_heads=num_heads, key_dim=embed_dim)\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L15\n",
    "        self.feed_forward = keras.Sequential([\n",
    "          layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
    "        \n",
    "        # L12\n",
    "        self.normalization_1  = layers.LayerNormalization()\n",
    "        # L14\n",
    "        self.normalization_2  = layers.LayerNormalization()\n",
    "        # L16\n",
    "        self.normalization_3  = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L11\n",
    "        attention_output_1 = self.attention_1(\n",
    "             query=inputs, value=inputs, key=inputs, attention_mask=causal_mask)\n",
    "        # L12\n",
    "        addnorm_output_1 = self.normalization_1(inputs + attention_output_1)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L13\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=addnorm_output_1, value=encoder_outputs, key=encoder_outputs,\n",
    "            attention_mask=padding_mask,)\n",
    "        # L14\n",
    "        addnorm_output_2 = self.normalization_2(addnorm_output_1 + attention_output_2)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L15\n",
    "        feedforward_output = self.feed_forward(addnorm_output_2)\n",
    "        # L16\n",
    "        addnorm_output_3 = self.normalization_3(addnorm_output_2 + feedforward_output)\n",
    "\n",
    "        return addnorm_output_3\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "        \n",
    "#*******************************************************************************\n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:35:14.665030Z",
     "iopub.status.busy": "2022-04-24T19:35:14.664595Z",
     "iopub.status.idle": "2022-04-24T19:35:16.523755Z",
     "shell.execute_reply": "2022-04-24T19:35:16.522560Z",
     "shell.execute_reply.started": "2022-04-24T19:35:14.664994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " positional_embedding_2 (Po  (None, None, 256)            3845120   ['encoder_inputs[0][0]']      \n",
      " sitionalEmbedding)                                                                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['positional_embedding_2[0][0]\n",
      " nsformerEncoder)                                                   ']                            \n",
      "                                                                                                  \n",
      " model_3 (Functional)        (None, None, 15000)          1295964   ['decoder_inputs[0][0]',      \n",
      "                                                          0          'transformer_encoder_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19960216 (76.14 MB)\n",
      "Trainable params: 19960216 (76.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "embed_dim  = 256\n",
    "latent_dim = 2048\n",
    "num_heads  = 8\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# L1\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "# L3, L4, L5\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# From L6 to L10\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "# Encoder\n",
    "encoder         = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# L2\n",
    "decoder_inputs     = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "# L10\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "# L3, L4, L5\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "# From L11 to L16\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Output Probabilities\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Decoder\n",
    "decoder         = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# My Transformer\n",
    "my_transformer = keras.Model(\n",
    "                          [encoder_inputs, decoder_inputs], \n",
    "                          decoder_outputs, name=\"my_transformer\")\n",
    "\n",
    "# The model’s summary() method displays all the model’s layers\n",
    "print(my_transformer.summary())\n",
    "\n",
    "# Plot the model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(my_transformer, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:35:16.527403Z",
     "iopub.status.busy": "2022-04-24T19:35:16.526391Z",
     "iopub.status.idle": "2022-04-24T19:35:41.186921Z",
     "shell.execute_reply": "2022-04-24T19:35:41.185760Z",
     "shell.execute_reply.started": "2022-04-24T19:35:16.527355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\risha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.22.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\risha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\risha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\risha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\risha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\risha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:35:41.195248Z",
     "iopub.status.busy": "2022-04-24T19:35:41.192837Z",
     "iopub.status.idle": "2022-04-24T21:05:01.038036Z",
     "shell.execute_reply": "2022-04-24T21:05:01.037055Z",
     "shell.execute_reply.started": "2022-04-24T19:35:41.195202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/my_transformer/transformer_encoder_1/multi_head_attention_3/softmax/add/BroadcastGradientArgs' defined at (most recent call last):\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 530, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\risha\\AppData\\Local\\Temp\\ipykernel_9332\\1124086770.py\", line 12, in <module>\n      history = my_transformer.fit(train_dataset, epochs=epochs, validation_data=val_dataset)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\optimizers\\weight_decay_optimizers.py\", line 168, in minimize\n      return super().minimize(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 598, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 656, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 532, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/my_transformer/transformer_encoder_1/multi_head_attention_3/softmax/add/BroadcastGradientArgs'\nIncompatible shapes: [256,8,20,20] vs. [256,256,20,20]\n\t [[{{node gradient_tape/my_transformer/transformer_encoder_1/multi_head_attention_3/softmax/add/BroadcastGradientArgs}}]] [Op:__inference_train_function_94088]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Training the model \u001b[39;00m\n\u001b[0;32m     11\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;66;03m# You have to train it longer to converge\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmy_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/my_transformer/transformer_encoder_1/multi_head_attention_3/softmax/add/BroadcastGradientArgs' defined at (most recent call last):\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 530, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\risha\\AppData\\Local\\Temp\\ipykernel_9332\\1124086770.py\", line 12, in <module>\n      history = my_transformer.fit(train_dataset, epochs=epochs, validation_data=val_dataset)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\optimizers\\weight_decay_optimizers.py\", line 168, in minimize\n      return super().minimize(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 598, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 656, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 532, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/my_transformer/transformer_encoder_1/multi_head_attention_3/softmax/add/BroadcastGradientArgs'\nIncompatible shapes: [256,8,20,20] vs. [256,256,20,20]\n\t [[{{node gradient_tape/my_transformer/transformer_encoder_1/multi_head_attention_3/softmax/add/BroadcastGradientArgs}}]] [Op:__inference_train_function_94088]"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "import tensorflow_addons as tfa\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate = 0.001, weight_decay=0.0001)\n",
    "\n",
    "# Compiling the model\n",
    "my_transformer.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                       optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "\n",
    "# Training the model \n",
    "epochs = 30 # You have to train it longer to converge\n",
    "history = my_transformer.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T21:06:04.920426Z",
     "iopub.status.busy": "2022-04-24T21:06:04.920133Z",
     "iopub.status.idle": "2022-04-24T21:06:05.188493Z",
     "shell.execute_reply": "2022-04-24T21:06:05.187551Z",
     "shell.execute_reply.started": "2022-04-24T21:06:04.920393Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the learning curves\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T21:08:04.339814Z",
     "iopub.status.busy": "2022-04-24T21:08:04.339331Z",
     "iopub.status.idle": "2022-04-24T21:08:25.740247Z",
     "shell.execute_reply": "2022-04-24T21:08:25.738071Z",
     "shell.execute_reply.started": "2022-04-24T21:08:04.339776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_dataset   = make_dataset(test_Russian)\n",
    "model_evaluate = my_transformer.evaluate(test_dataset)\n",
    "print(\"Loss     : \",model_evaluate[0])\n",
    "print(\"accuracy : \",model_evaluate[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T21:08:43.461301Z",
     "iopub.status.busy": "2022-04-24T21:08:43.460710Z",
     "iopub.status.idle": "2022-04-24T21:09:09.102875Z",
     "shell.execute_reply": "2022-04-24T21:09:09.101871Z",
     "shell.execute_reply.started": "2022-04-24T21:08:43.461257Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "fr_vocab = ru_vectorization.get_vocabulary()\n",
    "fr_index_lookup = dict(zip(range(len(fr_vocab)), fr_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = en_vectorization([input_sentence])\n",
    "\n",
    "    decoded_sentence = \"[start]\"\n",
    "\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = ru_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = my_transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fr_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "test_en_texts = [pair[0] for pair in test_Russian]\n",
    "exp = 0\n",
    "for i in range(30):\n",
    "    input_sentence = random.choice(test_en_texts)\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(\"Example : \",exp)\n",
    "    print(\"En: \",test_en_texts[i])\n",
    "\n",
    "    translated = translated.replace(\"[start]\", \"\")\n",
    "    translated = translated.replace(\"[UNK]\", \"\")\n",
    "    translated = translated.replace(\"end\", \"\")\n",
    "    print(\"Fr: \",translated)\n",
    "    exp = exp + 1\n",
    "    print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helped by https://github.com/hichemfelouat/my-codes-of-machine-learning/blob/master/Transformer_for_Translation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
